{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8bc6884",
   "metadata": {},
   "source": [
    "# Student Performance Dataset - Data Cleaning Pipeline\n",
    "\n",
    "This notebook demonstrates the comprehensive data cleaning process for student survey responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27abc4d",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This pipeline processes raw student survey data exported from Google Forms, applying comprehensive cleaning and standardization procedures. The dataset contains responses from 12,000+ students across various academic departments.\n",
    "\n",
    "\n",
    "### Key Processing Steps:**Primary Tools:** `pandas` for data manipulation, `numpy` for numerical operations\n",
    "\n",
    "- **Data validation and type conversion**\n",
    "\n",
    "- **Outlier detection and removal**- **Quality assurance and export**\n",
    "\n",
    "- **Missing value imputation**- **Text standardization and normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bf79d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully: 16,000 records\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data Loading and Initial Setup\n",
    "==============================\n",
    "Importing required libraries and loading the raw dataset for processing.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "std = pd.read_csv('../data/raw/forms_responses_12955.csv')\n",
    "print(f\"Dataset loaded successfully: {len(std):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a21f9",
   "metadata": {},
   "source": [
    "## Initial Data Exploration\n",
    "\n",
    "Examining the structure, quality, and characteristics of the raw dataset to inform our cleaning strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8017b137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample (10 records):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Satisfaction (1-5)</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14013</th>\n",
       "      <td>09/04/2023 06:02:00</td>\n",
       "      <td>STUD6791</td>\n",
       "      <td>22</td>\n",
       "      <td>Other</td>\n",
       "      <td>Zoo</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>09/26/2023 08:23:00</td>\n",
       "      <td>STUD5035</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geophysics</td>\n",
       "      <td>1.51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Comment 1825: The course was great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>09/25/2023 06:37:00</td>\n",
       "      <td>STUD7836</td>\n",
       "      <td>22</td>\n",
       "      <td>Other</td>\n",
       "      <td>Microbiology</td>\n",
       "      <td>3.59</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is spam... ignore me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11761</th>\n",
       "      <td>09/02/2023 22:32:00</td>\n",
       "      <td>STUD8387</td>\n",
       "      <td>21</td>\n",
       "      <td>Malee</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>3.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Comment 11761: The course was great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7503</th>\n",
       "      <td>09/04/2023 09:52:00</td>\n",
       "      <td>STUD5707</td>\n",
       "      <td>23</td>\n",
       "      <td>Other</td>\n",
       "      <td>Comp Sci</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This is spam... ignore me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12768</th>\n",
       "      <td>09/19/2023 09:36:00</td>\n",
       "      <td>STUD3679</td>\n",
       "      <td>22</td>\n",
       "      <td>Other</td>\n",
       "      <td>Microbiology</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This is spam... ignore me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>09/20/2023 11:06:00</td>\n",
       "      <td>STUD4286</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>Microbio</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Comment 6439: The course was great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>09/25/2023 08:36:00</td>\n",
       "      <td>STUD6226</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>3.96</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is spam... ignore me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>09/03/2023 00:19:00</td>\n",
       "      <td>STUD4790</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Comment 5852: The course was great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>09/29/2023 14:42:00</td>\n",
       "      <td>STUD6119</td>\n",
       "      <td>15</td>\n",
       "      <td>Other</td>\n",
       "      <td>Cell Biology and Genetics</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Comment 4468: The course was great!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp Student ID Age Gender                 Department  \\\n",
       "14013  09/04/2023 06:02:00   STUD6791  22  Other                        Zoo   \n",
       "1825   09/26/2023 08:23:00   STUD5035  22    NaN                 Geophysics   \n",
       "1284   09/25/2023 06:37:00   STUD7836  22  Other               Microbiology   \n",
       "11761  09/02/2023 22:32:00   STUD8387  21  Malee                  Chemistry   \n",
       "7503   09/04/2023 09:52:00   STUD5707  23  Other                   Comp Sci   \n",
       "12768  09/19/2023 09:36:00   STUD3679  22  Other               Microbiology   \n",
       "6439   09/20/2023 11:06:00   STUD4286  18   Male                   Microbio   \n",
       "9054   09/25/2023 08:36:00   STUD6226  19   Male               Biochemistry   \n",
       "5852   09/03/2023 00:19:00   STUD4790  22   Male               Biochemistry   \n",
       "4468   09/29/2023 14:42:00   STUD6119  15  Other  Cell Biology and Genetics   \n",
       "\n",
       "        GPA  Satisfaction (1-5)                              Comments  \n",
       "14013  0.21                 3.0                                   NaN  \n",
       "1825   1.51                 5.0   Comment 1825: The course was great!  \n",
       "1284   3.59                 4.0             This is spam... ignore me  \n",
       "11761  3.46                 1.0  Comment 11761: The course was great!  \n",
       "7503   0.93                 1.0             This is spam... ignore me  \n",
       "12768  2.87                 3.0             This is spam... ignore me  \n",
       "6439   3.27                 2.0   Comment 6439: The course was great!  \n",
       "9054   3.96                 5.0             This is spam... ignore me  \n",
       "5852   0.74                 5.0   Comment 5852: The course was great!  \n",
       "4468   1.01                 1.0   Comment 4468: The course was great!  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display random sample to understand data structure\n",
    "\n",
    "print(\"Random Sample (10 records):\")\n",
    "std.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce114e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Timestamp           16000 non-null  object \n",
      " 1   Student ID          16000 non-null  object \n",
      " 2   Age                 14769 non-null  object \n",
      " 3   Gender              15016 non-null  object \n",
      " 4   Department          15215 non-null  object \n",
      " 5   GPA                 14896 non-null  object \n",
      " 6   Satisfaction (1-5)  14845 non-null  float64\n",
      " 7   Comments            11174 non-null  object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 1000.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Examine dataset structure and data types\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "std.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe51eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satisfaction (1-5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14845.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.103941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.660700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Satisfaction (1-5)\n",
       "count        14845.000000\n",
       "mean             3.103941\n",
       "std              1.660700\n",
       "min              0.000000\n",
       "25%              2.000000\n",
       "50%              3.000000\n",
       "75%              4.000000\n",
       "max              7.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical summary of numerical columns\n",
    "\n",
    "print(\"Statistical Summary:\")\n",
    "std.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0467e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns:\n",
      " 1. Timestamp\n",
      " 2. Student ID\n",
      " 3. Age\n",
      " 4. Gender\n",
      " 5. Department\n",
      " 6. GPA\n",
      " 7. Satisfaction (1-5)\n",
      " 8. Comments\n"
     ]
    }
   ],
   "source": [
    "# Review column names for cleaning requirements\n",
    "\n",
    "print(\"Dataset Columns:\")    \n",
    "for i, col in enumerate(std.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b765267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Data Types:\n",
      "\n",
      "Object columns requiring type conversion: 7\n",
      "Timestamp              object\n",
      "Student ID             object\n",
      "Age                    object\n",
      "Gender                 object\n",
      "Department             object\n",
      "GPA                    object\n",
      "Satisfaction (1-5)    float64\n",
      "Comments               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Analyze current data types for conversion planning\n",
    "\n",
    "print(\"Current Data Types:\")\n",
    "print(f\"\\nObject columns requiring type conversion: {sum(std.dtypes == 'object')}\")\n",
    "print(std.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dfb3bc",
   "metadata": {},
   "source": [
    "## Data Cleaning Pipeline\n",
    "\n",
    "\n",
    "### 1. Timestamp StandardizationConverting timestamp data to proper datetime format and removing invalid entries to ensure temporal consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3eb7161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Original records: 16,000\n",
      "  Valid timestamps: 15,672\n",
      "  Records removed: 328\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp column to datetime format with error handling\n",
    "\n",
    "original_count = len(std)\n",
    "std['Timestamp'] = pd.to_datetime(std['Timestamp'], errors='coerce')\n",
    "\n",
    "# Remove records with invalid timestamps\n",
    "std.dropna(subset=['Timestamp'], inplace=True)\n",
    "cleaned_count = len(std)\n",
    "\n",
    "print(f\"  Original records: {original_count:,}\")\n",
    "print(f\"  Valid timestamps: {cleaned_count:,}\")\n",
    "print(f\"  Records removed: {original_count - cleaned_count:,}\")\n",
    "\n",
    "# Remove records with invalid timestampsprint(f\"Timestamp Processing:\")\n",
    "\n",
    "std.dropna(subset=['Timestamp'], inplace=True)\n",
    "cleaned_count = len(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff560ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15672 entries, 0 to 15999\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   Timestamp           15672 non-null  datetime64[ns]\n",
      " 1   Student ID          15672 non-null  object        \n",
      " 2   Age                 14470 non-null  object        \n",
      " 3   Gender              14706 non-null  object        \n",
      " 4   Department          14895 non-null  object        \n",
      " 5   GPA                 14596 non-null  object        \n",
      " 6   Satisfaction (1-5)  14539 non-null  float64       \n",
      " 7   Comments            10927 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#after using dropna and pd.to_datetime we check the info again\n",
    "std.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd1166",
   "metadata": {},
   "source": [
    "âœ… **Timestamp Processing Complete** - Successfully converted to datetime64[ns] format with temporal validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303bccad",
   "metadata": {},
   "source": [
    "### 2. Student ID Normalization\n",
    "\n",
    "Standardizing student identification format for consistency and data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bee348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample IDs: ['STUD2979', 'STUD8686', 'STUD4395']\n",
      "  Unique IDs: 7,397\n",
      "Student ID Processing:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Student ID Standardization:\n",
    "- Rename column for programmatic access\n",
    "- Convert to lowercase for consistency  \n",
    "- Remove leading/trailing whitespace\n",
    "\"\"\"\n",
    "\n",
    "print(f\"  Sample IDs: {list(std['Student ID'].dropna().head(3))}\")\n",
    "\n",
    "# Rename column to remove space (improves accessibility)\n",
    "std.rename(columns={'Student ID': 'Student_ID'}, inplace=True)\n",
    "print(f\"  Unique IDs: {std['Student_ID'].nunique():,}\")\n",
    "print(\"Student ID Processing:\")\n",
    "\n",
    "# Standardize format: lowercase and trimmed\n",
    "std['Student_ID'] = std['Student_ID'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cde849",
   "metadata": {},
   "source": [
    "### 3. Age Data Validation\n",
    "\n",
    "Converting age to numeric format, removing outliers, and ensuring realistic age ranges for academic participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8712bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Final age range: 15.0 - 100.0 years\n",
      "  Records with valid ages: 14,090\n",
      "Age Processing Statistics:\n",
      "  Age range before filtering: 15 - 100 years\n",
      "  Records after age filtering: 13,376\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Age Data Processing:\n",
    "- Convert to numeric format\n",
    "- Apply realistic age constraints (18-60 years)\n",
    "- Remove invalid/missing entries\n",
    "- Ensure integer type for age values\n",
    "\"\"\"\n",
    "\n",
    "# Convert to numeric, handling non-numeric entries\n",
    "original_count = len(std)\n",
    "std['Age'] = pd.to_numeric(std['Age'], errors='coerce')\n",
    "\n",
    "\n",
    "# Remove records with missing age dataprint(f\"  Mean age: {std['Age'].mean():.1f} years\")\n",
    "\n",
    "std.dropna(subset=['Age'], inplace=True)\n",
    "print(f\"  Final age range: {std['Age'].min()} - {std['Age'].max()} years\")\n",
    "\n",
    "after_numeric = len(std)\n",
    "print(f\"  Records with valid ages: {after_numeric:,}\")\n",
    "\n",
    "print(f\"Age Processing Statistics:\")\n",
    "\n",
    "print(f\"  Age range before filtering: {std['Age'].min():.0f} - {std['Age'].max():.0f} years\")\n",
    "std['Age'] = std['Age'].astype(int)\n",
    "\n",
    "# Convert to integer type (ages are whole numbers)\n",
    "\n",
    "# Apply realistic age constraints for students (18-60 years)\n",
    "\n",
    "std = std[(std['Age'] >= 18) & (std['Age'] <= 60)]\n",
    "final_count = len(std)\n",
    "print(f\"  Records after age filtering: {final_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e492ef",
   "metadata": {},
   "source": [
    "### 4. Gender Data Standardization\n",
    "\n",
    "Correcting typographical errors and standardizing gender categories with consistent formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d42c5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Gender Values:\n",
      "Gender\n",
      "Other     4035\n",
      "Male      4003\n",
      "Female    3997\n",
      "NaN        839\n",
      "Othr       179\n",
      "Malee      167\n",
      "Femal      156\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data type: string\n",
      "Gender\n",
      "Other     5053\n",
      "Male      4170\n",
      "Female    4153\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Standardized Gender Distribution:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gender Data Standardization:\n",
    "- Correct common typographical errors\n",
    "- Standardize missing values to 'Other'\n",
    "- Apply consistent title case formatting\n",
    "- Convert to string data type\n",
    "\"\"\"\n",
    "\n",
    "# Display original unique values for reference\n",
    "print(\"Original Gender Values:\")\n",
    "print(std['Gender'].value_counts(dropna=False))\n",
    "\n",
    "# Standardize gender categories and correct typos\n",
    "gender_mapping = {\n",
    "    'Femal': 'Female',\n",
    "    'Malee': 'Male', \n",
    "    'Othr': 'Other',\n",
    "    np.nan: 'Other'\n",
    "}\n",
    "\n",
    "std['Gender'] = std['Gender'].replace(gender_mapping)\n",
    "std['Gender'] = std['Gender'].fillna('Other')\n",
    "\n",
    "# Apply consistent formatting and data type\n",
    "\n",
    "std['Gender'] = std['Gender'].str.title().astype('string')\n",
    "print(f\"\\nData type: {std['Gender'].dtype}\")\n",
    "\n",
    "print(std['Gender'].value_counts())\n",
    "print(\"\\nStandardized Gender Distribution:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e38c05",
   "metadata": {},
   "source": [
    "### 5. Department Name Standardization\n",
    "\n",
    "Expanding abbreviated department names to full, standardized formats for better data clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfde6b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department Distribution:\n",
      "Department\n",
      "Zoology                      1093\n",
      "Geophysics                   1090\n",
      "Computer Science             1088\n",
      "Mathematics                  1077\n",
      "Microbiology                 1053\n",
      "Biochemistry                 1050\n",
      "Chemistry                    1040\n",
      "Cell Biology and Genetics    1040\n",
      "Physics                      1038\n",
      "Marine Sciences              1036\n",
      "Botany                        975\n",
      "Geology                       921\n",
      "Undeclared                    666\n",
      "Geosciences                   108\n",
      "Biology                       101\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Total departments: 15\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Department Standardization:\n",
    "- Expand common abbreviations to full names\n",
    "- Handle missing values with 'Undeclared' category\n",
    "- Ensure consistent naming conventions\n",
    "\"\"\"\n",
    "\n",
    "# Department name standardization mapping\n",
    "department_mapping = {\n",
    "    np.nan: 'Undeclared',\n",
    "    'Marine Sci': 'Marine Sciences',\n",
    "    'Geo': 'Geosciences', \n",
    "    'Biochem': 'Biochemistry',\n",
    "    'Maths': 'Mathematics',\n",
    "    'Phys': 'Physics',\n",
    "    'Bio': 'Biology',\n",
    "    'Cell Bio': 'Cell Biology and Genetics',\n",
    "    'Chem': 'Chemistry',\n",
    "    'Geophy': 'Geophysics',\n",
    "    'Zoo': 'Zoology', \n",
    "    'Microbio': 'Microbiology',\n",
    "    'Comp Sci': 'Computer Science'\n",
    "}\n",
    "\n",
    "# Apply standardization\n",
    "std['Department'] = std['Department'].replace(department_mapping)\n",
    "std['Department'] = std['Department'].fillna('Undeclared').astype('string')\n",
    "\n",
    "print(\"Department Distribution:\")\n",
    "\n",
    "print(std['Department'].value_counts())\n",
    "print(f\"\\nTotal departments: {std['Department'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efcbb4",
   "metadata": {},
   "source": [
    "### 6. GPA Conversion and Validation\n",
    "\n",
    "Converting letter grades to numeric values and applying data imputation for missing GPA entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d28ac72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPA Processing:\n",
      "  Unique values before conversion: ['-1.2', '0.0', '0.01', '0.02', '0.03', '0.04', '0.05', '0.06', '0.07', '0.08', '0.09', '0.1', '0.11', '0.12', '0.13', '0.14', '0.15', '0.16', '0.17', '0.18', '0.19', '0.2', '0.21', '0.22', '0.23', '0.24', '0.25', '0.26', '0.27', '0.28', '0.29', '0.3', '0.31', '0.32', '0.33', '0.34', '0.35', '0.36', '0.37', '0.38', '0.39', '0.4', '0.41', '0.42', '0.43', '0.44', '0.45', '0.46', '0.47', '0.48', '0.49', '0.5', '0.51', '0.52', '0.53', '0.54', '0.55', '0.56', '0.57', '0.58', '0.59', '0.6', '0.61', '0.62', '0.63', '0.64', '0.65', '0.66', '0.67', '0.68', '0.69', '0.7', '0.71', '0.72', '0.73', '0.74', '0.75', '0.76', '0.77', '0.78', '0.79', '0.8', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.9', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '1.0', '1.01', '1.02', '1.03', '1.04', '1.05', '1.06', '1.07', '1.08', '1.09', '1.1', '1.11', '1.12', '1.13', '1.14', '1.15', '1.16', '1.17', '1.18', '1.19', '1.2', '1.21', '1.22', '1.23', '1.24', '1.25', '1.26', '1.27', '1.28', '1.29', '1.3', '1.31', '1.32', '1.33', '1.34', '1.35', '1.36', '1.37', '1.38', '1.39', '1.4', '1.41', '1.42', '1.43', '1.44', '1.45', '1.46', '1.47', '1.48', '1.49', '1.5', '1.51', '1.52', '1.53', '1.54', '1.55', '1.56', '1.57', '1.58', '1.59', '1.6', '1.61', '1.62', '1.63', '1.64', '1.65', '1.66', '1.67', '1.68', '1.69', '1.7', '1.71', '1.72', '1.73', '1.74', '1.75', '1.76', '1.77', '1.78', '1.79', '1.8', '1.81', '1.82', '1.83', '1.84', '1.85', '1.86', '1.87', '1.88', '1.89', '1.9', '1.91', '1.92', '1.93', '1.94', '1.95', '1.96', '1.97', '1.98', '1.99', '2.0', '2.01', '2.02', '2.03', '2.04', '2.05', '2.06', '2.07', '2.08', '2.09', '2.1', '2.11', '2.12', '2.13', '2.14', '2.15', '2.16', '2.17', '2.18', '2.19', '2.2', '2.21', '2.22', '2.23', '2.24', '2.25', '2.26', '2.27', '2.28', '2.29', '2.3', '2.31', '2.32', '2.33', '2.34', '2.35', '2.36', '2.37', '2.38', '2.39', '2.4', '2.41', '2.42', '2.43', '2.44', '2.45', '2.46', '2.47', '2.48', '2.49', '2.5', '2.51', '2.52', '2.53', '2.54', '2.55', '2.56', '2.57', '2.58', '2.59', '2.6', '2.61', '2.62', '2.63', '2.64', '2.65', '2.66', '2.67', '2.68', '2.69', '2.7', '2.71', '2.72', '2.73', '2.74', '2.75', '2.76', '2.77', '2.78', '2.79', '2.8', '2.81', '2.82', '2.83', '2.84', '2.85', '2.86', '2.87', '2.88', '2.89', '2.9', '2.91', '2.92', '2.93', '2.94', '2.95', '2.96', '2.97', '2.98', '2.99', '3.0', '3.01', '3.02', '3.03', '3.04', '3.05', '3.06', '3.07', '3.08', '3.09', '3.1', '3.11', '3.12', '3.13', '3.14', '3.15', '3.16', '3.17', '3.18', '3.19', '3.2', '3.21', '3.22', '3.23', '3.24', '3.25', '3.26', '3.27', '3.28', '3.29', '3.3', '3.31', '3.32', '3.33', '3.34', '3.35', '3.36', '3.37', '3.38', '3.39', '3.4', '3.41', '3.42', '3.43', '3.44', '3.45', '3.46', '3.47', '3.48', '3.49', '3.5', '3.51', '3.52', '3.53', '3.54', '3.55', '3.56', '3.57', '3.58', '3.59', '3.6', '3.61', '3.62', '3.63', '3.64', '3.65', '3.66', '3.67', '3.68', '3.69', '3.7', '3.71', '3.72', '3.73', '3.74', '3.75', '3.76', '3.77', '3.78', '3.79', '3.8', '3.81', '3.82', '3.83', '3.84', '3.85', '3.86', '3.87', '3.88', '3.89', '3.9', '3.91', '3.92', '3.93', '3.94', '3.95', '3.96', '3.97', '3.98', '3.99', '4.0', '5.0', 'A']\n",
      "  Final GPA range: -1.2 - 5.0\n",
      "  Missing values imputed: 916\n",
      "  Records removed (GPA < 1.0): 3188\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GPA Processing Pipeline:\n",
    "- Convert letter grades to numeric equivalents\n",
    "- Apply linear interpolation for missing values\n",
    "- Remove outliers below minimum threshold\n",
    "- Round to two decimal places for consistency\n",
    "\"\"\"\n",
    "\n",
    "# Letter grade to numeric GPA conversion (5.0 scale)\n",
    "grade_mapping = {\n",
    "    'A': 4.5, 'B': 3.5, 'C': 3.0, 'D': 2.5, 'F': 1.5\n",
    "}\n",
    "\n",
    "print(\"GPA Processing:\")\n",
    "print(f\"  Unique values before conversion: {sorted(std['GPA'].dropna().unique())}\")\n",
    "\n",
    "# Apply grade mapping and convert to numeric\n",
    "std['GPA'] = std['GPA'].replace(grade_mapping)\n",
    "std['GPA'] = pd.to_numeric(std['GPA'], errors='coerce')\n",
    "\n",
    "\n",
    "# Handle missing values with linear interpolationprint(f\"  Mean GPA: {std['GPA'].mean():.2f}\")\n",
    "\n",
    "missing_before = std['GPA'].isna().sum()\n",
    "print(f\"  Final GPA range: {std['GPA'].min()} - {std['GPA'].max()}\")\n",
    "\n",
    "std['GPA'] = std['GPA'].fillna(std['GPA'].interpolate(method='linear'))\n",
    "std['GPA'] = std['GPA'].round(2)\n",
    "print(f\"  Missing values imputed: {missing_before}\")\n",
    "\n",
    "before_filter = len(std)\n",
    "std = std[std['GPA'] >= 1.0]\n",
    "after_filter = len(std)\n",
    "print(f\"  Records removed (GPA < 1.0): {before_filter - after_filter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b25b14e",
   "metadata": {},
   "source": [
    "### 7. Satisfaction Score Processing\n",
    "\n",
    "Applying data imputation and validation to satisfaction ratings on a 1-5 scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e1355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9908 entries, 1 to 15999\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   Timestamp           9908 non-null   datetime64[ns]\n",
      " 1   Student_ID          9908 non-null   object        \n",
      " 2   Age                 9908 non-null   int64         \n",
      " 3   Gender              9908 non-null   string        \n",
      " 4   Department          9908 non-null   string        \n",
      " 5   GPA                 9908 non-null   float64       \n",
      " 6   Satisfaction (1-5)  9908 non-null   float64       \n",
      " 7   Comments            6894 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(2), string(2)\n",
      "memory usage: 696.7+ KB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Satisfaction Score Validation:\n",
    "- Apply linear interpolation for missing values\n",
    "- Ensure scores fall within valid range (1-5)\n",
    "- Round to two decimal places\n",
    "\"\"\"\n",
    "\n",
    "print(f\"  Mean satisfaction: {std['Satisfaction (1-5)'].mean():.2f}\")\n",
    "\n",
    "# Process satisfaction scores\n",
    "print(f\"  Score range: {std['Satisfaction (1-5)'].min()} - {std['Satisfaction (1-5)'].max()}\")\n",
    "\n",
    "missing_satisfaction = std['Satisfaction (1-5)'].isna().sum()\n",
    "print(f\"  Missing values imputed: {missing_satisfaction}\")\n",
    "\n",
    "# Fill missing values using linear interpolation\n",
    "std['Satisfaction (1-5)'] = std['Satisfaction (1-5)'].interpolate(method='linear')\n",
    "\n",
    "# Round to two decimal places\n",
    "std['Satisfaction (1-5)'] = std['Satisfaction (1-5)'].round(2)\n",
    "\n",
    "before_filter = len(std)\n",
    "# Remove invalid scores (below minimum threshold)\n",
    "std = std[std['Satisfaction (1-5)'] >= 1.0]\n",
    "after_filter = len(std)\n",
    "print(f\"  Records removed (score < 1.0): {before_filter - after_filter}\")\n",
    "\n",
    "print(\"Satisfaction Score Processing:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55da0873",
   "metadata": {},
   "source": [
    "### 8. Comment Text Standardization\n",
    "\n",
    "Normalizing comment format and handling spam detection for consistent text data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f38db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment Processing Summary:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comment Standardization Pipeline:\n",
    "- Handle missing values with default positive comment\n",
    "- Detect and filter spam content\n",
    "- Apply consistent formatting with sequential IDs\n",
    "- Sort by timestamp for chronological ordering\n",
    "\"\"\"\n",
    "\n",
    "# Sort by timestamp for consistent comment indexing\n",
    "std = std.sort_values('Timestamp', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Fill missing comments with neutral default\n",
    "std['Comments'] = std['Comments'].fillna(\"The course was great!\")\n",
    "\n",
    "def standardize_comment(idx, text):\n",
    "    \"\"\"\n",
    "    Standardize comment format and handle spam detection.\n",
    "    \n",
    "    Args:\n",
    "        idx: Sequential comment index\n",
    "        text: Original comment text\n",
    "    \n",
    "    Returns:\n",
    "        Formatted comment string with consistent structure\n",
    "    \"\"\"\n",
    "    if isinstance(text, str) and text.startswith('This is spam'):\n",
    "        return f'Comment {idx}: The course was great!'  # Replace spam\n",
    "    elif isinstance(text, str) and text.startswith('Comment'):\n",
    "        # Extract existing comment content\n",
    "        parts = text.split(':', 1)\n",
    "        content = parts[1].strip() if len(parts) > 1 else 'No comment'\n",
    "        return f'Comment {idx}: {content}'\n",
    "\n",
    "    elif isinstance(text, str) and text.strip():\n",
    "        return f'Comment {idx}: {text.strip()}'  # Format new comment\n",
    "\n",
    "    else:\n",
    "        return f'Comment {idx}: No comment'  # Handle empty/invalid\n",
    "\n",
    "print(\"Comment Processing Summary:\")\n",
    "\n",
    "# Apply standardization and convert to string type\n",
    "\n",
    "std['Comments'] = [standardize_comment(i, txt) for i, txt in enumerate(std['Comments'])]\n",
    "std['Comments'] = std['Comments'].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c782445",
   "metadata": {},
   "source": [
    "## Data Export and Finalization\n",
    "\n",
    "Exporting the cleaned dataset in multiple formats for analysis and distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36e41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ ../data/cleaned/cleaned_student_data.csv\n",
      "  âœ“ ../data/cleaned/cleaned_student_data.xlsx\n",
      "\n",
      "Files exported:\n",
      "  Average satisfaction: 3.11\n",
      "  Average GPA: 2.64\n",
      "  Departments: 15\n",
      "  Age range: 18-25 years\n",
      "  Date range: 2023-09-01 to 2023-09-30\n",
      "  Columns processed: 8\n",
      "  Total records: 10,188\n",
      "Final dataset statistics:\n",
      "\n",
      "============================================================\n",
      "============================================================\n",
      "           DATA CLEANING PIPELINE COMPLETE\n",
      "           DATA CLEANING PIPELINE COMPLETE\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Final Data Export:\n",
    "- Save cleaned dataset as CSV for compatibility\n",
    "\n",
    "- Export Excel format with descriptive sheet nameprint(\"\\nDataset ready for analysis! ðŸš€\")\n",
    "\n",
    "- Provide comprehensive cleaning summaryprint(f\"  âœ“ {output_excel}\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "output_csv = '../data/cleaned/cleaned_student_data.csv'\n",
    "output_excel = '../data/cleaned/cleaned_student_data.xlsx'\n",
    "\n",
    "std.to_csv(output_csv, index=False)\n",
    "std.to_excel(output_excel, index=False, sheet_name='Cleaned Student Data')\n",
    "\n",
    "print(f\"  âœ“ {output_csv}\")\n",
    "print(f\"  âœ“ {output_excel}\")\n",
    "print(f\"\\nFiles exported:\")\n",
    "print(f\"  Average satisfaction: {std['Satisfaction (1-5)'].mean():.2f}\")\n",
    "print(f\"  Average GPA: {std['GPA'].mean():.2f}\")\n",
    "print(f\"  Departments: {std['Department'].nunique()}\")\n",
    "print(f\"  Age range: {std['Age'].min()}-{std['Age'].max()} years\")\n",
    "print(f\"  Date range: {std['Timestamp'].min().date()} to {std['Timestamp'].max().date()}\")\n",
    "print(f\"  Columns processed: {len(std.columns)}\")\n",
    "print(f\"  Total records: {len(std):,}\")\n",
    "print(f\"Final dataset statistics:\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"=\"*60)\n",
    "print(\"           DATA CLEANING PIPELINE COMPLETE\")\n",
    "print(\"           DATA CLEANING PIPELINE COMPLETE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
